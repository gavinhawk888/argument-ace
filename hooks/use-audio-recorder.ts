"use client"

import { useState, useEffect, useCallback, useRef } from "react"
import { useToast } from "@/hooks/use-toast"

export function useAudioRecorder() {
  const [isRecording, setIsRecording] = useState(false)
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null)
  const [transcript, setTranscript] = useState<string>("")
  const [isProcessing, setIsProcessing] = useState(false)
  const [hasError, setHasError] = useState(false)
  const { toast } = useToast()
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const processingRef = useRef<boolean>(false) // é˜²é‡å¤å¤„ç†æ ‡å¿—

  // é‡ç½®æ‰€æœ‰çŠ¶æ€
  const resetStates = useCallback(() => {
    setIsRecording(false)
    setAudioBlob(null)
    setTranscript("")
    setIsProcessing(false)
    setHasError(false)
    processingRef.current = false // é‡ç½®å¤„ç†æ ‡å¿—
  }, [])

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    try {
      // é‡ç½®ä¹‹å‰çš„çŠ¶æ€
      resetStates()
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 44100,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      })
      
      // æ£€æŸ¥æ”¯æŒçš„MIMEç±»åž‹
      let mimeType = 'audio/webm;codecs=opus'
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm'
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/mp4'
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = ''
          }
        }
      }
      
      console.log('ðŸŽ¤ ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', mimeType)
      
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType || undefined,
        audioBitsPerSecond: 128000
      })
      
      audioChunksRef.current = []
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }
      
      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { 
          type: mimeType || 'audio/webm' 
        })
        setAudioBlob(audioBlob)
        
        // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
        stream.getTracks().forEach(track => track.stop())
        
        // ä¸åœ¨è¿™é‡Œè°ƒç”¨processAudioï¼Œè®©é¡µé¢çš„useEffectå¤„ç†
        // await processAudio(audioBlob)
      }
      
      mediaRecorderRef.current = mediaRecorder
      mediaRecorder.start(1000) // æ¯ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®
      setIsRecording(true)
      
      toast({
        title: "å½•éŸ³å¼€å§‹",
        description: "è¯·æ¸…æ™°åœ°è¯´è¯ï¼Œæˆ‘ä»¬æ­£åœ¨ç›‘å¬...",
      })
    } catch (error) {
      console.error('Start recording error:', error)
      setHasError(true)
      toast({
        variant: "destructive",
        title: "å½•éŸ³å¤±è´¥",
        description: "æ— æ³•è®¿é—®éº¦å…‹é£Žï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®",
      })
    }
  }, [toast, resetStates])

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
      // ä¸åœ¨è¿™é‡Œè®¾ç½®isProcessingï¼Œè®©processAudioå‡½æ•°è‡ªå·±ç®¡ç†
      // setIsProcessing(true)
      
      toast({
        title: "å½•éŸ³ç»“æŸ",
        description: "æ­£åœ¨å¤„ç†éŸ³é¢‘ï¼Œè¯·ç¨å€™...",
      })
    }
  }, [isRecording, toast])

  // å¤„ç†éŸ³é¢‘è¯†åˆ«
  const processAudio = useCallback(async (audioBlob: Blob, selectedLanguage?: string) => {
    if (processingRef.current) return
    processingRef.current = true
    setIsProcessing(true) // å¼€å§‹å¤„ç†æ—¶è®¾ç½®ä¸ºtrue
    try {
      // èŽ·å–ç”¨æˆ·è¯­è¨€åå¥½ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„è¯­è¨€å‚æ•°
      const userLanguage = selectedLanguage || navigator.language || 'en-US'
      
      // åªåœ¨å¼€å‘çŽ¯å¢ƒä¸­è°ƒè¯•éŸ³é¢‘æ•°æ®
      if (process.env.NODE_ENV === 'development') {
        console.log('ðŸ” å¼€å§‹è°ƒè¯•éŸ³é¢‘æ•°æ®...')
        const debugResponse = await fetch('/api/debug-audio', {
          method: 'POST',
          body: audioBlob,
          headers: {
            'Content-Type': 'audio/webm',
            'X-Language': userLanguage
          }
        })
        
        if (debugResponse.ok) {
          const debugInfo = await debugResponse.json()
          console.log('ðŸ” éŸ³é¢‘è°ƒè¯•ä¿¡æ¯:', debugInfo)
          
          // å¦‚æžœéŸ³é¢‘æœ‰é—®é¢˜ï¼Œæ˜¾ç¤ºè­¦å‘Š
          if (debugInfo.recommendations && debugInfo.recommendations.length > 0) {
            console.warn('âš ï¸ éŸ³é¢‘é—®é¢˜:', debugInfo.recommendations)
            toast({
              variant: "destructive",
              title: "éŸ³é¢‘è´¨é‡è­¦å‘Š",
              description: debugInfo.recommendations.join('; '),
            })
          }
        }
      }
      
      // é¦–å…ˆå°è¯•çœŸå®žçš„è¯­éŸ³è¯†åˆ«APIï¼Œä¼ é€’è¯­è¨€å‚æ•°
      let response = await fetch('/api/speech', {
        method: 'POST',
        body: audioBlob,
        headers: {
          'Content-Type': 'audio/webm',
          'X-Language': userLanguage
        }
      })
      
      let result = await response.json()
      
      // å¦‚æžœçœŸå®žAPIå¤±è´¥ï¼Œå°è¯•æµ‹è¯•API
      if (!response.ok || result.error) {
        console.log('Real API failed, trying test API:', result.error)
        
        response = await fetch('/api/test-speech', {
          method: 'POST',
          body: audioBlob,
          headers: {
            'Content-Type': 'audio/webm',
            'X-Language': userLanguage
          }
        })
        
        result = await response.json()
        
        if (result.isMock) {
          toast({
            title: "ä½¿ç”¨æ¨¡æ‹Ÿè¯†åˆ«",
            description: "çœŸå®žAPIä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«",
          })
        }
      }
      
      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`)
      }
      
      if (result.error) {
        throw new Error(result.error)
      }
      
      // å¦‚æžœæœ‰è°ƒè¯•ä¿¡æ¯ï¼Œè¾“å‡ºåˆ°æŽ§åˆ¶å°
      if (result.debug) {
        console.log('ðŸ› APIè°ƒè¯•ä¿¡æ¯:', result.debug)
      }
      
      setTranscript(result.transcript || "")
      
      if (result.transcript) {
        // å¤„ç†è¯­è¨€æ£€æµ‹ç»“æžœ
        let detectedLang = result.selectedLanguage || userLanguage
        let languageInfo = ""
        
        if (result.detectedLanguages && result.detectedLanguages.length > 0) {
          // æ–°çš„å¤šè¯­è¨€APIå“åº”
          detectedLang = result.detectedLanguages[0] // ä½¿ç”¨æœ€ä¸»è¦çš„è¯­è¨€
          
          if (result.detectedLanguages.length > 1) {
            // å¤šè¯­è¨€æ··åˆ
            languageInfo = `æ£€æµ‹åˆ°å¤šè¯­è¨€ï¼š${result.detectedLanguages.join(', ')}`
          } else {
            languageInfo = `æ£€æµ‹åˆ°è¯­è¨€ï¼š${result.detectedLanguages[0]}`
          }
          
          // å¦‚æžœæœ‰å•è¯çº§åˆ«çš„è¯­è¨€ä¿¡æ¯ï¼Œæ˜¾ç¤ºæ›´è¯¦ç»†çš„ä¿¡æ¯
          if (result.wordsWithLanguages && result.wordsWithLanguages.length > 0) {
            const languageCounts = result.wordsWithLanguages.reduce((acc: Record<string, number>, word: any) => {
              acc[word.language] = (acc[word.language] || 0) + 1
              return acc
            }, {})
            
            const languageStats = Object.entries(languageCounts)
              .map(([lang, count]) => `${lang}(${count}è¯)`)
              .join(', ')
            
            languageInfo = `è¯­è¨€åˆ†å¸ƒï¼š${languageStats}`
          }
        } else if (result.detectedLanguage) {
          // å…¼å®¹æ—§çš„å•è¯­è¨€APIå“åº”
          detectedLang = result.detectedLanguage
          languageInfo = `æ£€æµ‹åˆ°è¯­è¨€ï¼š${result.detectedLanguage}`
        }
        
        const isChineseDetected = detectedLang.includes('zh')
        
        toast({
          title: isChineseDetected ? "è¯†åˆ«å®Œæˆ" : "Recognition Complete",
          description: isChineseDetected 
            ? `${languageInfo}\nè¯†åˆ«åˆ°ï¼š${result.transcript.substring(0, 50)}${result.transcript.length > 50 ? '...' : ''}`
            : `${languageInfo}\nRecognized: ${result.transcript.substring(0, 50)}${result.transcript.length > 50 ? '...' : ''}`,
        })
        
        // åœ¨æŽ§åˆ¶å°è¾“å‡ºè¯¦ç»†çš„å¤šè¯­è¨€ä¿¡æ¯
        if (result.detectedLanguages) {
          console.log('ðŸŒ å¤šè¯­è¨€è¯†åˆ«ç»“æžœ:')
          console.log('  æ£€æµ‹åˆ°çš„è¯­è¨€:', result.detectedLanguages)
          console.log('  ç½®ä¿¡åº¦:', result.confidence)
          
          if (result.wordsWithLanguages) {
            console.log('  å•è¯çº§è¯­è¨€ä¿¡æ¯:')
            result.wordsWithLanguages.forEach((word: any, index: number) => {
              console.log(`    ${index + 1}. "${word.word}" (${word.language}, ç½®ä¿¡åº¦: ${word.confidence?.toFixed(2) || 'N/A'})`)
            })
          }
        }
      } else {
        // è¯†åˆ«åˆ°ç©ºå†…å®¹ä¹Ÿç®—ä½œé”™è¯¯
        setHasError(true)
        
        // å¦‚æžœæœ‰è°ƒè¯•ä¿¡æ¯ï¼Œæ˜¾ç¤ºæ›´è¯¦ç»†çš„é”™è¯¯
        let errorMessage = "æœªèƒ½è¯†åˆ«åˆ°æœ‰æ•ˆçš„è¯­éŸ³å†…å®¹"
        if (result.debug) {
          errorMessage += `\nè°ƒè¯•ä¿¡æ¯: éŸ³é¢‘å¤§å°=${result.debug.audioSize}å­—èŠ‚, å¤„ç†æ—¶é—´=${result.debug.processingTime}ms`
        }
        
        toast({
          variant: "destructive", 
          title: "éŸ³é¢‘è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•ï¼",
          description: errorMessage,
        })
      }
    } catch (error) {
      console.error('Audio processing error:', error)
      setHasError(true)
      toast({
        variant: "destructive",
        title: "éŸ³é¢‘è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•ï¼", 
        description: "éŸ³é¢‘å¤„ç†è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯ï¼š" + (error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'),
      })
    } finally {
      setIsProcessing(false)
      processingRef.current = false
    }
  }, [toast])

  // æ£€æŸ¥éº¦å…‹é£Žæƒé™
  const checkMicrophonePermission = useCallback(async () => {
    try {
      if (typeof navigator === 'undefined' || !navigator.mediaDevices) {
        toast({
          variant: "destructive",
          title: "æµè§ˆå™¨ä¸æ”¯æŒ",
          description: "æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å½•åˆ¶åŠŸèƒ½",
        })
        return false
      }

      await navigator.mediaDevices.getUserMedia({ audio: true })
      return true
    } catch (err) {
      if (err instanceof Error) {
        const message = err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError'
          ? "è¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£Žè®¿é—®æƒé™"
          : "è®¿é—®éº¦å…‹é£Žæ—¶å‡ºçŽ°é”™è¯¯"

        toast({
          variant: "destructive",
          title: "éº¦å…‹é£Žè®¿é—®è¢«æ‹’ç»",
          description: message,
        })
      }
      return false
    }
  }, [toast])

  // æ¸…ç†å‡½æ•°
  useEffect(() => {
    return () => {
      if (mediaRecorderRef.current && isRecording) {
        mediaRecorderRef.current.stop()
      }
    }
  }, [isRecording])

  return {
    isRecording,
    audioBlob,
    transcript,
    isProcessing,
    hasError,
    startRecording,
    stopRecording,
    processAudio,
    checkMicrophonePermission,
    resetStates
  }
}