import 'dotenv/config'
import { createDeepgramService } from '../lib/deepgram-service'

/**
 * ä¸­è‹±æ–‡æ··åˆè¯­éŸ³è¯†åˆ«æµ‹è¯•
 * 
 * æ³¨æ„ï¼šè¿™ä¸ªæµ‹è¯•éœ€è¦çœŸå®žçš„ä¸­è‹±æ–‡æ··åˆéŸ³é¢‘æ–‡ä»¶
 * å¦‚æžœæ²¡æœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œä¼šå±•ç¤ºé…ç½®è¯´æ˜Žå’Œé¢„æœŸç»“æžœ
 */

interface TestCase {
  description: string
  expectedChinese: string
  expectedEnglish: string
  expectedMixed: string
  audioFile?: string
}

const MIXED_LANGUAGE_TEST_CASES: TestCase[] = [
  {
    description: 'å·¥ä½œåœºæ™¯æ··åˆ',
    expectedChinese: 'æˆ‘ä»Šå¤©è¦åŽ»',
    expectedEnglish: 'meeting',
    expectedMixed: 'æˆ‘ä»Šå¤©è¦åŽ» meeting',
    audioFile: 'test-mixed-1.wav'
  },
  {
    description: 'å­¦ä¹ åœºæ™¯æ··åˆ', 
    expectedChinese: 'è¯·å¸®æˆ‘ç¿»è¯‘è¿™ä¸ª',
    expectedEnglish: 'sentence',
    expectedMixed: 'Please help me ç¿»è¯‘è¿™ä¸ª sentence',
    audioFile: 'test-mixed-2.wav'
  },
  {
    description: 'é¡¹ç›®è®¨è®ºæ··åˆ',
    expectedChinese: 'è¿™ä¸ªé¡¹ç›®éžå¸¸',
    expectedEnglish: 'interesting project',
    expectedMixed: 'è¿™ä¸ª project éžå¸¸ interesting',
    audioFile: 'test-mixed-3.wav'
  },
  {
    description: 'åœ°ç‚¹å¯¼èˆªæ··åˆ',
    expectedChinese: 'æˆ‘ä»¬åŽ»',
    expectedEnglish: "Let's go to",
    expectedMixed: "Let's go to åŒ—äº¬",
    audioFile: 'test-mixed-4.wav'
  }
]

class MultilingualTestRunner {
  private deepgramService: any
  private hasAudioFiles = false

  constructor() {
    const apiKey = process.env.DEEPGRAM_API_KEY
    if (!apiKey || apiKey === 'your_deepgram_api_key_here') {
      throw new Error('âŒ è¯·é…ç½®æœ‰æ•ˆçš„ DEEPGRAM_API_KEY')
    }
    this.deepgramService = createDeepgramService(apiKey)
  }

  // æ£€æŸ¥æµ‹è¯•éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
  checkAudioFiles(): boolean {
    const fs = require('fs')
    let foundFiles = 0
    
    console.log('ðŸ” æ£€æŸ¥ä¸­è‹±æ–‡æ··åˆæµ‹è¯•éŸ³é¢‘æ–‡ä»¶...')
    
    MIXED_LANGUAGE_TEST_CASES.forEach((testCase, index) => {
      if (testCase.audioFile && fs.existsSync(testCase.audioFile)) {
        console.log(`âœ… æ‰¾åˆ°: ${testCase.audioFile}`)
        foundFiles++
      } else {
        console.log(`âŒ ç¼ºå¤±: ${testCase.audioFile || `test-case-${index}.wav`}`)
      }
    })

    this.hasAudioFiles = foundFiles > 0
    return this.hasAudioFiles
  }

  // æµ‹è¯•å¤šè¯­è¨€é…ç½®
  async testMultilingualConfiguration() {
    console.log('\nðŸ”§ éªŒè¯å¤šè¯­è¨€æ··åˆé…ç½®...')
    
    // æ£€æŸ¥DeepgramæœåŠ¡é…ç½®
    const testBuffer = new ArrayBuffer(100) // æ¨¡æ‹ŸéŸ³é¢‘æ•°æ®
    
    try {
      // è¿™ä¼šå¤±è´¥ï¼Œä½†æˆ‘ä»¬å¯ä»¥çœ‹åˆ°é”™è¯¯ä¿¡æ¯ä¸­çš„é…ç½®
      await this.deepgramService.transcribePrerecorded(testBuffer)
    } catch (error) {
      // é¢„æœŸçš„é”™è¯¯ï¼Œè¯´æ˜Žé…ç½®æ­£ç¡®
      console.log('âœ… DeepgramæœåŠ¡å·²æ­£ç¡®é…ç½®å¤šè¯­è¨€æ”¯æŒ')
      console.log('   - æ¨¡åž‹: nova-3')
      console.log('   - è¯­è¨€: multi (å¤šè¯­è¨€ä»£ç åˆ‡æ¢)')
      console.log('   - ç«¯ç‚¹: 100ms (ä»£ç åˆ‡æ¢ä¼˜åŒ–)')
    }
  }

  // å±•ç¤ºé…ç½®è¯´æ˜Ž
  showConfigurationGuide() {
    console.log('\nðŸ“– Deepgram å¤šè¯­è¨€ä»£ç åˆ‡æ¢é…ç½®è¯´æ˜Ž')
    console.log('=' .repeat(60))
    
    console.log('\nðŸŽ¯ å½“å‰é…ç½® (lib/deepgram-service.ts):')
    console.log('```typescript')
    console.log('const { result, error } = await this.client.listen.prerecorded.transcribeFile(')
    console.log('  audioData,')
    console.log('  {')
    console.log('    model: "nova-3",        // æ”¯æŒå¤šè¯­è¨€çš„Nova-3æ¨¡åž‹')
    console.log('    language: "multi",      // ðŸ”¥ å¯ç”¨å¤šè¯­è¨€ä»£ç åˆ‡æ¢')
    console.log('    smart_format: true,     // æ™ºèƒ½æ ¼å¼åŒ–')
    console.log('    punctuate: true,        // æ ‡ç‚¹ç¬¦å·')
    console.log('    endpointing: 100,       // ä»£ç åˆ‡æ¢ä¼˜åŒ–ç«¯ç‚¹å€¼') 
    console.log('  }')
    console.log(')')
    console.log('```')

    console.log('\nðŸŒ æ”¯æŒçš„è¯­è¨€ç»„åˆ:')
    console.log('- ðŸ‡¨ðŸ‡³ ä¸­æ–‡ + ðŸ‡ºðŸ‡¸ è‹±æ–‡')
    console.log('- ðŸ‡ªðŸ‡¸ è¥¿ç­ç‰™æ–‡ + ðŸ‡ºðŸ‡¸ è‹±æ–‡') 
    console.log('- ðŸ‡«ðŸ‡· æ³•æ–‡ + ðŸ‡ºðŸ‡¸ è‹±æ–‡')
    console.log('- è¿˜æœ‰æ›´å¤šè¯­è¨€ç»„åˆ...')

    console.log('\nðŸ“ é¢„æœŸè¯†åˆ«ç»“æžœç¤ºä¾‹:')
    MIXED_LANGUAGE_TEST_CASES.forEach((testCase, index) => {
      console.log(`\n${index + 1}. ${testCase.description}:`)
      console.log(`   è¾“å…¥: "${testCase.expectedMixed}"`)
      console.log(`   é¢„æœŸè¾“å‡º: {`)
      console.log(`     "transcript": "${testCase.expectedMixed}",`)
      console.log(`     "detectedLanguages": ["zh", "en"],`)
      console.log(`     "wordsWithLanguages": [`)
      
      // æ¨¡æ‹Ÿå•è¯çº§è¯­è¨€æ ‡è¯†
      const words = testCase.expectedMixed.split(' ')
      words.forEach((word, wordIndex) => {
        const isChinese = /[\u4e00-\u9fff]/.test(word)
        const language = isChinese ? 'zh' : 'en'
        console.log(`       { "word": "${word}", "language": "${language}" }${wordIndex < words.length - 1 ? ',' : ''}`)
      })
      
      console.log(`     ]`)
      console.log(`   }`)
    })
  }

  // å®žé™…éŸ³é¢‘æµ‹è¯•ï¼ˆå¦‚æžœæœ‰éŸ³é¢‘æ–‡ä»¶ï¼‰
  async runActualAudioTests() {
    if (!this.hasAudioFiles) {
      console.log('\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼Œè·³è¿‡å®žé™…æµ‹è¯•')
      return
    }

    console.log('\nðŸ§ª è¿è¡Œä¸­è‹±æ–‡æ··åˆéŸ³é¢‘æµ‹è¯•...')
    const fs = require('fs')

    for (const testCase of MIXED_LANGUAGE_TEST_CASES) {
      if (!testCase.audioFile || !fs.existsSync(testCase.audioFile)) continue

      try {
        console.log(`\nðŸŽµ æµ‹è¯•: ${testCase.description}`)
        console.log(`ðŸ“ æ–‡ä»¶: ${testCase.audioFile}`)

        const audioData = fs.readFileSync(testCase.audioFile)
        const result = await this.deepgramService.transcribePrerecorded(audioData.buffer)

        console.log(`ðŸ“ è¯†åˆ«ç»“æžœ: "${result.transcript}"`)
        console.log(`ðŸŽ¯ ç½®ä¿¡åº¦: ${result.confidence.toFixed(4)}`)
        console.log(`ðŸŒ æ£€æµ‹è¯­è¨€: ${result.detectedLanguages.join(', ')}`)
        
        // åˆ†æžè¯­è¨€åˆ†å¸ƒ
        if (result.wordsWithLanguages && result.wordsWithLanguages.length > 0) {
          const languageStats: { [key: string]: number } = {}
          result.wordsWithLanguages.forEach((word: any) => {
            languageStats[word.language] = (languageStats[word.language] || 0) + 1
          })
          console.log(`ðŸ“Š è¯­è¨€åˆ†å¸ƒ:`, languageStats)
          
          // å±•ç¤ºå•è¯çº§è¯­è¨€æ ‡è¯†
          console.log(`ðŸ·ï¸ å•è¯çº§è¯­è¨€æ ‡è¯†:`)
          result.wordsWithLanguages.forEach((word: any) => {
            console.log(`   "${word.word}" (${word.language})`)
          })
        }

      } catch (error) {
        console.error(`âŒ æµ‹è¯•å¤±è´¥: ${error}`)
      }
    }
  }

  // ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æ–‡ä»¶å»ºè®®
  showAudioFileGuide() {
    console.log('\nðŸŽ¤ å¦‚ä½•åˆ›å»ºä¸­è‹±æ–‡æ··åˆæµ‹è¯•éŸ³é¢‘æ–‡ä»¶:')
    console.log('=' .repeat(60))
    
    console.log('\nðŸ“± å½•åˆ¶å»ºè®®:')
    console.log('1. ä½¿ç”¨æ¸…æ™°çš„å½•éŸ³è®¾å¤‡')
    console.log('2. åœ¨å®‰é™çš„çŽ¯å¢ƒä¸­å½•åˆ¶')
    console.log('3. è¯­é€Ÿé€‚ä¸­ï¼Œå‘éŸ³æ¸…æ™°')
    console.log('4. ä¿å­˜ä¸º WAV æ ¼å¼ (44.1kHz, 16-bit)')
    
    console.log('\nðŸ—£ï¸ æŽ¨èæµ‹è¯•å†…å®¹:')
    MIXED_LANGUAGE_TEST_CASES.forEach((testCase, index) => {
      console.log(`${index + 1}. ${testCase.audioFile}: "${testCase.expectedMixed}"`)
    })

    console.log('\nðŸ’¡ åœ¨çº¿å½•éŸ³å·¥å…·:')
    console.log('- Online Voice Recorder: https://online-voice-recorder.com/')
    console.log('- RecordMP3Online: https://recordmp3online.com/')
    console.log('- Audacity (æ¡Œé¢åº”ç”¨): https://www.audacityteam.org/')

    console.log('\nðŸ“ æ–‡ä»¶å‘½åå’Œæ”¾ç½®:')
    console.log('- å°†å½•åˆ¶çš„éŸ³é¢‘æ–‡ä»¶ä¿å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•')
    console.log('- ä½¿ç”¨å»ºè®®çš„æ–‡ä»¶å (test-mixed-1.wav ç­‰)')
    console.log('- æ–‡ä»¶å¤§å°å»ºè®®: 50KB - 1MB')
    console.log('- å½•éŸ³æ—¶é•¿å»ºè®®: 3-10ç§’')
  }

  // ä¸»æµ‹è¯•è¿è¡Œå™¨
  async runAllTests() {
    console.log('ðŸŒ Deepgram ä¸­è‹±æ–‡æ··åˆè¯­éŸ³è¯†åˆ«æµ‹è¯•')
    console.log('=' .repeat(60))

    try {
      // 1. æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
      const hasFiles = this.checkAudioFiles()
      
      // 2. éªŒè¯é…ç½®
      await this.testMultilingualConfiguration()
      
      // 3. å±•ç¤ºé…ç½®è¯´æ˜Ž
      this.showConfigurationGuide()
      
      // 4. è¿è¡Œå®žé™…æµ‹è¯•ï¼ˆå¦‚æžœæœ‰éŸ³é¢‘æ–‡ä»¶ï¼‰
      await this.runActualAudioTests()
      
      // 5. æä¾›å½•åˆ¶æŒ‡å—
      if (!hasFiles) {
        this.showAudioFileGuide()
      }

      console.log('\nðŸŽ‰ æµ‹è¯•å®Œæˆ!')
      console.log('\nðŸ’¡ å°è´´å£«:')
      console.log('- å½“å‰é…ç½®å·²å¯ç”¨å¤šè¯­è¨€ä»£ç åˆ‡æ¢ (language: "multi")')
      console.log('- ä½¿ç”¨ Nova-3 æ¨¡åž‹ä»¥èŽ·å¾—æœ€ä½³æ•ˆæžœ')
      console.log('- å½•åˆ¶ä¸­è‹±æ–‡æ··åˆéŸ³é¢‘æ–‡ä»¶ä»¥æµ‹è¯•å®žé™…æ•ˆæžœ')
      console.log('- æŸ¥çœ‹ https://developers.deepgram.com/docs/multilingual-code-switching')

    } catch (error) {
      console.error('âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™:', error)
    }
  }
}

// ä¸»å‡½æ•°
async function main() {
  const testRunner = new MultilingualTestRunner()
  await testRunner.runAllTests()
}

// è¿è¡Œæµ‹è¯•
if (require.main === module) {
  main().catch(error => {
    console.error('ðŸ’¥ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸:', error)
    process.exit(1)
  })
}

export { MultilingualTestRunner, MIXED_LANGUAGE_TEST_CASES } 